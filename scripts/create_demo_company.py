#!/usr/bin/env python3
"""
Demo Company Setup Script

Creates a demo company (team) with N welcomepage users from scratch.
Each user has a complete welcomepage with different headers, all available tiles,
and a variety of prompts.

This script is designed to generate the EXACT same team content each time it runs
(with the same parameters). All random selections (wave GIFs, prompts, answers, etc.)
are deterministic based on user index, ensuring consistent test data generation.

Note: Public IDs (team and user) are constructed from the --prefix parameter:
- Team ID: {prefix}team01 (e.g., "ibm-team01" or "dem1team01")
- User IDs: {prefix}001, {prefix}002, etc. (e.g., "ibm-001" or "dem1001")
All content (names, roles, locations, prompts, answers, wave GIFs, etc.) will be identical
when using the same prefix and team size.

Usage:
    # Create demo company:
    python create_demo_company.py --team-name "Acme Corp" --prefix "ibm-" --initial-email "user+2000@gmail.com" --logo-url "https://example.com/logo.png" [--team-size 15]
    python create_demo_company.py --team-name "Acme Corp" --prefix "dem1" --initial-email "user+2000@gmail.com" --logo-file "/path/to/logo.png" [--team-size 15]
    
    # Remove demo company:
    python create_demo_company.py --prefix "ibm-" --remove [--dry-run]
    python create_demo_company.py --prefix "dem1" --remove [--dry-run]

Examples:
    # Create:
    python create_demo_company.py --team-name "TechStart Inc" --prefix "ibm-" --initial-email "charles.barton+2000@gmail.com" --logo-url "https://xastkogrfeblbsvmbkew.supabase.co/storage/v1/object/public/test_wave_gif_library/company-logo.png" --team-size 10
    python create_demo_company.py --team-name "TechStart Inc" --prefix "dem1" --initial-email "charles.barton+2000@gmail.com" --logo-file "./logo.png" --team-size 10
    
    # Remove:
    python create_demo_company.py --prefix "ibm-" --remove
    python create_demo_company.py --prefix "dem1" --remove --dry-run

Note: The initial-email must follow the pattern <email>+<number>@gmail.com. 
      The first user will get ADMIN role, subsequent users will get USER role.
      Auth emails will be generated by incrementing the number (e.g., user+2000, user+2001, user+2002, ...)
"""

import argparse
import random
import requests
import os
import sys
import asyncio
import json
import re
from typing import List, Dict, Any, Set, Tuple
from sqlalchemy.orm import Session

# Add the parent directory to the path so we can import our modules
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Load environment variables from .env file
from dotenv import load_dotenv
load_dotenv()

from database import SessionLocal
from models.team import Team
from models.welcomepage_user import WelcomepageUser
from utils.supabase_storage import upload_to_supabase_storage, delete_from_supabase_storage
from utils.logger_factory import new_logger

# Initialize logger
log = new_logger("create_demo_company")

# Wave GIF library configuration
WAVE_GIF_LIBRARY_BASE_URL = "https://xastkogrfeblbsvmbkew.supabase.co/storage/v1/object/public/test_wave_gif_library"
WAVE_GIF_COUNT = 21  # We have test_wave_gif1.gif through test_wave_gif21.gif

def check_public_id_collisions(
    db: Session,
    team_public_id: str,
    user_public_ids: List[str]
) -> Tuple[bool, List[str]]:
    """
    Check if any of the proposed public IDs already exist in the database.
    
    Args:
        db: Database session
        team_public_id: Proposed team public ID
        user_public_ids: List of proposed user public IDs
        
    Returns:
        Tuple of (has_collisions, list_of_colliding_ids)
    """
    collisions = []
    
    # Check team ID
    existing_team = db.query(Team).filter_by(public_id=team_public_id).first()
    if existing_team:
        collisions.append(f"Team ID '{team_public_id}' already exists (Team: {existing_team.organization_name})")
    
    # Check user IDs
    for user_id in user_public_ids:
        existing_user = db.query(WelcomepageUser).filter_by(public_id=user_id).first()
        if existing_user:
            collisions.append(f"User ID '{user_id}' already exists (User: {existing_user.name})")
    
    return len(collisions) > 0, collisions

def check_auth_email_collisions(
    db: Session,
    auth_emails: List[str]
) -> Tuple[bool, List[str]]:
    """
    Check if any of the proposed auth_emails already exist in the database.
    
    Args:
        db: Database session
        auth_emails: List of proposed auth_email addresses
        
    Returns:
        Tuple of (has_collisions, list_of_colliding_emails)
    """
    collisions = []
    
    # Check each auth_email
    for auth_email in auth_emails:
        existing_user = db.query(WelcomepageUser).filter_by(auth_email=auth_email).first()
        if existing_user:
            collisions.append(f"Auth email '{auth_email}' already exists (User: {existing_user.name}, Public ID: {existing_user.public_id})")
    
    return len(collisions) > 0, collisions

# Hardcoded team member data for consistency
# Each entry: (name, role, location, greeting, nickname, prompts_dict)
# Note: Public IDs are now constructed from prefix + index (e.g., {prefix}001, {prefix}002, etc.)
# Locations include USA, Canada, and Western Europe
# Prompts and answers are hardcoded for complete determinism
TEAM_MEMBERS = [
    (
        "Alex Chen", "Senior Software Engineer", "San Francisco, CA, USA", "Hey there!", "Alex",
        {
            "What's your superpower at work?": "I can turn complex problems into simple, actionable steps. It helps the team move forward when we're stuck on challenging projects.",
            "What's your favorite way to spend a weekend?": "Hiking with my dog and then trying a new restaurant in the evening. Perfect balance of activity and relaxation!",
            "What's your go-to productivity hack?": "Time blocking my calendar with specific tasks rather than general 'work time'. It helps me stay focused and track progress.",
            "I geek out onâ€¦": "Vintage synthesizers and electronic music production. I have a small home studio with some classic gear.",
        }
    ),
    (
        "Sarah Taylor", "Product Manager", "London, UK", "Hi everyone!", "Sarah",
        {
            "What's your superpower at work?": "I'm the team's documentation wizard! I make sure our knowledge is captured and accessible to everyone.",
            "What's something unexpected about you?": "I used to be a professional chess player before getting into tech. The strategic thinking definitely helps in my current role!",
            "What's a book/podcast that changed your perspective?": "The 'How I Built This' podcast showed me that every successful company started with someone just trying to solve a problem.",
            "When I do my best work (deepâ€‘work hours vs. collaboration and meetings)": "I'm a morning person, so I do my best deep work between 7-11am. Afternoons are for collaboration and meetings.",
        }
    ),
    (
        "Marcus Lee", "UX Designer", "Seattle, WA, USA", "Hello!", "Marcus",
        {
            "What's your superpower at work?": "Definitely my ability to bring different perspectives together. I can usually find common ground when opinions differ.",
            "What's your favorite way to spend a weekend?": "I'm part of a community garden and spend most weekends there. It's my meditation and social time rolled into one.",
            "What's a skill you're currently learning?": "I'm learning to play the guitar. It's been a great way to unwind after work and exercise a different part of my brain.",
            "My simple pleasuresâ€¦": "A perfectly brewed cup of coffee in the morning, a good book before bed, and Sunday morning farmers markets.",
        }
    ),
    (
        "Samuel Rivera", "DevOps Engineer", "Toronto, ON, Canada", "Hey!", "Sam",
        {
            "What's something unexpected about you?": "I can speak five languages! I grew up in an international community and picked them up along the way.",
            "What's your go-to productivity hack?": "The Pomodoro technique changed my life! 25 minutes of focused work followed by a 5-minute break works perfectly for my brain.",
            "What's a book/podcast that changed your perspective?": "'Atomic Habits' completely changed how I approach building new skills and breaking bad habits.",
            "What I need from teammates to do great work": "Clear requirements and context. I do my best work when I understand the 'why' behind what we're building.",
        }
    ),
    (
        "Sophia Kim", "Frontend Developer", "Amsterdam, Netherlands", "Hi there!", "Sophia",
        {
            "What's your favorite way to spend a weekend?": "Board game marathons with friends! We're currently obsessed with strategy games that take hours to play.",
            "What's a skill you're currently learning?": "I'm taking a course on machine learning. It's fascinating to see how AI can be applied to solve real-world problems.",
            "I geek out onâ€¦": "Astrophotography. I love capturing images of deep space objects with my telescope and camera setup.",
            "When I do my best work (deepâ€‘work hours vs. collaboration and meetings)": "I need complete silence for focused work, so I block 2-4pm every day for heads-down coding. Mornings are for standups and planning.",
        }
    ),
    (
        "Jessica Patel", "Backend Developer", "Boston, MA, USA", "Hello everyone!", "Jessica",
        {
            "What's your superpower at work?": "I excel at debugging complex systems. Give me a production issue and I'll track it down faster than anyone.",
            "What's your go-to productivity hack?": "I use the 'two-minute rule' - if something takes less than two minutes, I do it immediately instead of adding it to a todo list.",
            "What's a book/podcast that changed your perspective?": "'The Design of Everyday Things' opened my eyes to how important good UX is in everything we interact with.",
            "What I need from teammates to do great work": "Quick responses to questions. I'd rather ask a quick question than spend hours going down the wrong path.",
        }
    ),
    (
        "Katherine Wong", "Data Scientist", "Berlin, Germany", "Hey!", "Katherine",
        {
            "What's something unexpected about you?": "I'm a certified scuba diving instructor. I've dived in over 20 countries around the world.",
            "What's your favorite way to spend a weekend?": "Exploring local museums and art galleries. There's always something new to discover even in familiar places.",
            "What's a skill you're currently learning?": "I'm learning Spanish through Duolingo. My goal is to be conversational by the end of the year.",
            "My simple pleasuresâ€¦": "The smell of rain on hot pavement, finding a new favorite song, and that first bite of a really good sandwich.",
        }
    ),
    (
        "Ryan Johnson", "QA Engineer", "Vancouver, BC, Canada", "Hi!", "Ryan",
        {
            "What's your superpower at work?": "My superpower is breaking down large features into manageable chunks and keeping everyone aligned on the roadmap.",
            "What's your go-to productivity hack?": "I start every day by writing down my top 3 priorities. Everything else can wait until those are done.",
            "I geek out onâ€¦": "Mechanical keyboards. I've built several custom keyboards and love the sound and feel of different switches.",
            "When I do my best work (deepâ€‘work hours vs. collaboration and meetings)": "I'm most productive late at night (10pm-2am). During the day, I'm better at meetings and collaborative work.",
        }
    ),
    (
        "Quentin Martinez", "Technical Writer", "Portland, OR, USA", "Hello there!", "Quentin",
        {
            "What's something unexpected about you?": "I used to perform stand-up comedy at local clubs. It taught me a lot about reading an audience and timing.",
            "What's your favorite way to spend a weekend?": "Cooking elaborate meals from scratch. I love trying new recipes and techniques from different cuisines.",
            "What's a book/podcast that changed your perspective?": "The 'Freakonomics' podcast made me think differently about cause and effect in the world around us.",
            "What I need from teammates to do great work": "Honest feedback, especially early in the process. It's much easier to pivot early than to redo work later.",
        }
    ),
    (
        "Brooke Thompson", "Security Engineer", "Paris, France", "Hey everyone!", "Brooke",
        {
            "What's your superpower at work?": "I can turn complex problems into simple, actionable steps. It helps the team move forward when we're stuck on challenging projects.",
            "What's your go-to productivity hack?": "I batch similar tasks together. All my meetings in one block, all my coding in another, all my emails in another.",
            "What's a skill you're currently learning?": "I'm teaching myself woodworking. I just finished building my first bookshelf and I'm hooked!",
            "I geek out onâ€¦": "Coffee brewing methods. I'm always experimenting with different beans, grind sizes, and brewing techniques.",
        }
    ),
    (
        "Drew Garcia", "Mobile Developer", "Austin, TX, USA", "Hi!", "Drew",
        {
            "What's something unexpected about you?": "I'm a competitive rock climber. I've climbed some of the most challenging routes in Yosemite.",
            "What's a skill you're currently learning?": "I'm learning to cook authentic Italian cuisine. My carbonara is getting pretty good, if I do say so myself.",
            "My simple pleasuresâ€¦": "Watching the sunset from my balcony, fresh sheets on the bed, and unexpected compliments from strangers.",
            "When I do my best work (deepâ€‘work hours vs. collaboration and meetings)": "I split my day: deep work in the morning (9am-12pm), meetings in the afternoon (1-4pm), then more focused work (4-6pm).",
        }
    ),
    (
        "Amelia Smith", "Product Designer", "Dublin, Ireland", "Hello!", "Amelia",
        {
            "What's your favorite way to spend a weekend?": "Hiking with my dog and then trying a new restaurant in the evening. Perfect balance of activity and relaxation!",
            "What's a book/podcast that changed your perspective?": "'Thinking, Fast and Slow' by Daniel Kahneman made me much more aware of my own cognitive biases and decision-making processes.",
            "I geek out onâ€¦": "Retro video game consoles. I collect and restore old systems, and I'm working on a complete NES library.",
            "What I need from teammates to do great work": "Time to focus without interruptions. I appreciate when people respect my 'do not disturb' hours.",
        }
    ),
    (
        "Emma Brown", "Full Stack Developer", "Montreal, QC, Canada", "Hey there!", "Emma",
        {
            "What's your superpower at work?": "I'm the team's documentation wizard! I make sure our knowledge is captured and accessible to everyone.",
            "What's your go-to productivity hack?": "Time blocking my calendar with specific tasks rather than general 'work time'. It helps me stay focused and track progress.",
            "My simple pleasuresâ€¦": "The sound of birds in the morning, a warm shower after a long day, and laughing until my stomach hurts.",
            "When I do my best work (deepâ€‘work hours vs. collaboration and meetings)": "I do my best coding work in the afternoon (2-6pm). Mornings are for emails, standups, and lighter tasks.",
        }
    ),
    (
        "Sage Williams", "Engineering Manager", "Barcelona, Spain", "Hi everyone!", "Sage",
        {
            "What's your superpower at work?": "Definitely my ability to bring different perspectives together. I can usually find common ground when opinions differ.",
            "What's something unexpected about you?": "I can speak five languages! I grew up in an international community and picked them up along the way.",
            "What's a skill you're currently learning?": "I'm learning to play the guitar. It's been a great way to unwind after work and exercise a different part of my brain.",
            "What I need from teammates to do great work": "Trust and autonomy. Give me the problem to solve and let me figure out the best approach.",
        }
    ),
    (
        "Olivia Davis", "Site Reliability Engineer", "New York, NY, USA", "Hello!", "Olivia",
        {
            "What's your favorite way to spend a weekend?": "I'm part of a community garden and spend most weekends there. It's my meditation and social time rolled into one.",
            "What's your go-to productivity hack?": "The Pomodoro technique changed my life! 25 minutes of focused work followed by a 5-minute break works perfectly for my brain.",
            "My simple pleasuresâ€¦": "A clean workspace, the perfect temperature in my apartment, and catching up with old friends.",
            "When I do my best work (deepâ€‘work hours vs. collaboration and meetings)": "I'm a morning person, so I do my best deep work between 7-11am. Afternoons are for collaboration and meetings.",
        }
    ),
]

# Team public ID will be constructed from prefix: {prefix}team01
# User public IDs will be constructed from prefix: {prefix}001, {prefix}002, etc.

# Sample Spotify URLs (playlists, tracks, shows) - one per user
# Use tracks and albums primarily - they're more likely to be public and accessible
# Playlists can be private and return 404, so we use fewer of them
SAMPLE_SPOTIFY_URLS = [
    "https://open.spotify.com/track/3bE5slaVEfaDreqARl6k4M",  # Pearl Jam - Yellow Ledbetter (known working track)
    "https://open.spotify.com/track/5VSCgNlSmTV2Yq5lB40Eaw",  # Popular track
    "https://open.spotify.com/album/1ATL5GLyefJaxhQzSPVrLX",  # Popular album
    "https://open.spotify.com/track/3n3Ppam7vgaVa1iaRUc9Lp",  # Popular track
    "https://open.spotify.com/show/4rOoJ6Egrf8K2IrywzwOMk",  # Popular podcast
    "https://open.spotify.com/track/5y38S3svDxqF4fmPaUxp8R",  # Popular track
    "https://open.spotify.com/album/4yP0hdKOZ4sh7Nk7ZMVlvm",  # Popular album
    "https://open.spotify.com/track/1Je1IMUlBXcx1Fz0WE7oPT",  # Popular track
    "https://open.spotify.com/show/1VXcH8QHkjRcTCEd88U3ti",  # Popular podcast
    "https://open.spotify.com/album/6ZvDJs17O3woQirttKRYCG",  # Popular album
    "https://open.spotify.com/track/2VxeLyX666F8uXCJ0dZF8B",  # Popular track
    "https://open.spotify.com/show/2MAi0BvDc6GTFvKFPXnkCl",  # Popular podcast
    "https://open.spotify.com/album/3mH6qwIy9crq0I9YQbOuDf",  # Popular album
    "https://open.spotify.com/track/0VjIjW4GlU5U4D1y1z3iNi",  # Popular track
    "https://open.spotify.com/album/1y8NcY4wTqL1zH5z1JmJ9J",  # Popular album
]

# Sample YouTube URLs - one per user
SAMPLE_YOUTUBE_URLS = [
    "https://www.youtube.com/watch?v=dQw4w9WgXcQ",  # Classic video
    "https://www.youtube.com/watch?v=9bZkp7q19f0",  # Popular video
    "https://www.youtube.com/watch?v=kJQP7kiw5Fk",  # Popular video
    "https://www.youtube.com/watch?v=fJ9rUzIMcZQ",  # Popular video
    "https://www.youtube.com/watch?v=OPf0YbXqDm0",  # Popular video
    "https://www.youtube.com/watch?v=LXb3EKWsInQ",  # Popular video
    "https://www.youtube.com/watch?v=ZbZSe6N_BXs",  # Popular video
    "https://www.youtube.com/watch?v=ScMzIvxBSi4",  # Popular video
    "https://www.youtube.com/watch?v=2Vv-BfVoq4g",  # Popular video
    "https://www.youtube.com/watch?v=YQHsXMglC9A",  # Popular video
    "https://www.youtube.com/watch?v=FTQbiNvZqaY",  # Popular video
    "https://www.youtube.com/watch?v=ZbZSe6N_BXs",  # Popular video
    "https://www.youtube.com/watch?v=ScMzIvxBSi4",  # Popular video
    "https://www.youtube.com/watch?v=2Vv-BfVoq4g",  # Popular video
    "https://www.youtube.com/watch?v=YQHsXMglC9A",  # Popular video
]

# City coordinates for location widgets
# Format: (city_name, lat, lng)
CITY_COORDINATES = {
    "San Francisco, CA, USA": (37.7749, -122.4194),
    "London, UK": (51.5074, -0.1278),
    "Seattle, WA, USA": (47.6062, -122.3321),
    "Toronto, ON, Canada": (43.6532, -79.3832),
    "Amsterdam, Netherlands": (52.3676, 4.9041),
    "Boston, MA, USA": (42.3601, -71.0589),
    "Berlin, Germany": (52.5200, 13.4050),
    "Vancouver, BC, Canada": (49.2827, -123.1207),
    "Portland, OR, USA": (45.5152, -122.6784),
    "Paris, France": (48.8566, 2.3522),
    "Austin, TX, USA": (30.2672, -97.7431),
    "Dublin, Ireland": (53.3498, -6.2603),
    "Montreal, QC, Canada": (45.5017, -73.5673),
    "Barcelona, Spain": (41.3851, 2.1734),
    "New York, NY, USA": (40.7128, -74.0060),
}

# Nearby cities within ~300km for "born and raised" locations
# Format: current_city -> list of nearby cities
NEARBY_CITIES = {
    "San Francisco, CA, USA": [
        ("San Jose, CA, USA", 37.3382, -121.8863),
        ("Oakland, CA, USA", 37.8044, -122.2712),
        ("Sacramento, CA, USA", 38.5816, -121.4944),
    ],
    "London, UK": [
        ("Cambridge, UK", 52.2053, 0.1218),
        ("Oxford, UK", 51.7520, -1.2577),
        ("Brighton, UK", 50.8225, -0.1372),
    ],
    "Seattle, WA, USA": [
        ("Tacoma, WA, USA", 47.2529, -122.4443),
        ("Everett, WA, USA", 47.9789, -122.2021),
        ("Bellevue, WA, USA", 47.6101, -122.2015),
    ],
    "Toronto, ON, Canada": [
        ("Hamilton, ON, Canada", 43.2557, -79.8711),
        ("Mississauga, ON, Canada", 43.5890, -79.6441),
        ("Oakville, ON, Canada", 43.4675, -79.6877),
    ],
    "Amsterdam, Netherlands": [
        ("Utrecht, Netherlands", 52.0907, 5.1214),
        ("Haarlem, Netherlands", 52.3792, 4.6332),
        ("Rotterdam, Netherlands", 51.9244, 4.4777),
    ],
    "Boston, MA, USA": [
        ("Cambridge, MA, USA", 42.3736, -71.1097),
        ("Worcester, MA, USA", 42.2626, -71.8023),
        ("Providence, RI, USA", 41.8240, -71.4128),
    ],
    "Berlin, Germany": [
        ("Potsdam, Germany", 52.3906, 13.0645),
        ("Brandenburg, Germany", 52.4125, 12.5316),
        ("Cottbus, Germany", 51.7563, 14.3329),
    ],
    "Vancouver, BC, Canada": [
        ("Burnaby, BC, Canada", 49.2488, -122.9805),
        ("Richmond, BC, Canada", 49.1666, -123.1367),
        ("Surrey, BC, Canada", 49.1913, -122.8490),
    ],
    "Portland, OR, USA": [
        ("Salem, OR, USA", 44.9429, -123.0351),
        ("Eugene, OR, USA", 44.0521, -123.0868),
        ("Vancouver, WA, USA", 45.6387, -122.6615),
    ],
    "Paris, France": [
        ("Versailles, France", 48.8049, 2.1204),
        ("OrlÃ©ans, France", 47.9029, 1.9093),
        ("Reims, France", 49.2583, 4.0317),
    ],
    "Austin, TX, USA": [
        ("San Antonio, TX, USA", 29.4241, -98.4936),
        ("Round Rock, TX, USA", 30.5083, -97.6789),
        ("Georgetown, TX, USA", 30.6333, -97.6772),
    ],
    "Dublin, Ireland": [
        ("Cork, Ireland", 51.8985, -8.4756),
        ("Limerick, Ireland", 52.6638, -8.6268),
        ("Galway, Ireland", 53.2707, -9.0568),
    ],
    "Montreal, QC, Canada": [
        ("Laval, QC, Canada", 45.6067, -73.7129),
        ("Longueuil, QC, Canada", 45.5369, -73.5103),
        ("Quebec City, QC, Canada", 46.8139, -71.2080),
    ],
    "Barcelona, Spain": [
        ("Girona, Spain", 41.9794, 2.8214),
        ("Tarragona, Spain", 41.1189, 1.2445),
        ("Lleida, Spain", 41.6176, 0.6200),
    ],
    "New York, NY, USA": [
        ("Newark, NJ, USA", 40.7357, -74.1724),
        ("Jersey City, NJ, USA", 40.7178, -74.0431),
        ("Yonkers, NY, USA", 40.9312, -73.8988),
    ],
}

def get_location_data(location: str) -> dict:
    """Get location data (lat, lng) for a given location string."""
    if location in CITY_COORDINATES:
        lat, lng = CITY_COORDINATES[location]
        # Extract city name from location string
        city_name = location.split(',')[0]
        return {
            "placeId": f"demo-{city_name.lower().replace(' ', '-')}",
            "name": city_name,
            "address": location,
            "lat": lat,
            "lng": lng,
            "mapUrl": f"/api/google/staticmap?center={lat},{lng}&zoom=10&size=300x200"
        }
    # Fallback: return None if location not found
    return None

def get_nearby_birth_location(current_location: str, user_index: int) -> dict:
    """Get a nearby city for 'born and raised' location within ~300km of current location."""
    if current_location in NEARBY_CITIES:
        nearby_options = NEARBY_CITIES[current_location]
        # Use user_index to deterministically select a nearby city
        selected_city = nearby_options[user_index % len(nearby_options)]
        city_name, lat, lng = selected_city
        return {
            "placeId": f"demo-{city_name.lower().replace(' ', '-')}",
            "name": city_name,
            "address": selected_city[0],  # Full address string
            "lat": lat,
            "lng": lng,
            "mapUrl": f"/api/google/staticmap?center={lat},{lng}&zoom=10&size=300x200"
        }
    # Fallback: use current location if no nearby cities defined
    return get_location_data(current_location)

# Available bento widget types (from widget-selector.tsx)
BENTO_WIDGET_TYPES = [
    {'id': 'location', 'name': 'Born and raised', 'component': 'location', 'defaultSize': '1x1'},
    {'id': 'current-location', 'name': 'Where I live now', 'component': 'current-location', 'defaultSize': '1x1'},
    {'id': 'photo-v2', 'name': 'My favourite people / pets', 'component': 'photo-v2', 'defaultSize': '1x2'},
    {'id': 'spotify', 'name': "I'm listening to...", 'component': 'spotify', 'defaultSize': '2x1'},
    {'id': 'video', 'name': "I'm watching...", 'component': 'video', 'defaultSize': '2x2'},
    {'id': 'fun-activities', 'name': "When I'm not at work...", 'component': 'fun-activities', 'defaultSize': '2x1'},
]

def get_wave_gif_url_for_user(user_index: int) -> str:
    """Get a deterministic wave GIF URL for a user based on their index."""
    # Use user_index to deterministically select a GIF
    # User 1 (index 0) gets test_wave_gif1.gif, user 10 (index 9) gets test_wave_gif10.gif, etc.
    # If user_index exceeds available GIFs, wrap around
    gif_number = (user_index % WAVE_GIF_COUNT) + 1  # +1 to get range 1-21
    return f"{WAVE_GIF_LIBRARY_BASE_URL}/test_wave_gif{gif_number}.gif"

def get_photo_v2_url_for_user(user_index: int) -> str:
    """Get the photo-v2 image URL from the library for a user based on their index."""
    # Images in the library are named: demo001-favorite-people.jpg, demo002-favorite-people.jpg, etc.
    # Use hardcoded demo IDs (demo001, demo002, etc.) regardless of the prefix used for database public_ids
    demo_id = f"demo{user_index+1:03d}"  # demo001, demo002, etc.
    return f"{WAVE_GIF_LIBRARY_BASE_URL}/{demo_id}-favorite-people.jpg"

def get_photo_v2_caption(user_index: int) -> str:
    """Get the appropriate caption for the photo-v2 widget based on user index."""
    # Pet types: 1-4 = dogs, 5-8 = cats, 9-12 = aquarium fish, 13-15 = pet birds
    if user_index < 4:  # 0-3 (demo001-demo004)
        return "My favorite dogs"
    elif user_index < 8:  # 4-7 (demo005-demo008)
        return "My favorite cats"
    elif user_index < 12:  # 8-11 (demo009-demo012)
        return "My aquarium fish"
    else:  # 12-14 (demo013-demo015)
        return "My pet birds"

def download_wave_gif(gif_url: str) -> bytes:
    """Download a wave GIF from the library."""
    try:
        response = requests.get(gif_url, timeout=30)
        response.raise_for_status()
        gif_content = response.content
        file_size_mb = len(gif_content) / 1024 / 1024
        log.info(f"Successfully downloaded wave GIF from {gif_url} ({file_size_mb:.2f} MB)")
        
        # Check file size limit (5MB to stay under Supabase 6MB limit with overhead)
        MAX_FILE_SIZE = 5 * 1024 * 1024  # 5MB in bytes
        if len(gif_content) > MAX_FILE_SIZE:
            log.warning(f"Wave GIF exceeds size limit ({file_size_mb:.2f} MB > 5 MB). This file will fail to upload.")
            log.warning(f"Consider replacing {gif_url} with a smaller version or removing it from the library.")
        
        return gif_content
    except requests.RequestException as e:
        log.error(f"Failed to download wave GIF from {gif_url}: {e}")
        raise

async def clone_wave_gif_to_user(gif_content: bytes, user_public_id: str) -> str:
    """Clone a wave GIF to the user's storage location."""
    # Check file size before attempting upload
    MAX_FILE_SIZE = 5 * 1024 * 1024  # 5MB in bytes
    file_size_mb = len(gif_content) / 1024 / 1024
    
    if len(gif_content) > MAX_FILE_SIZE:
        error_msg = f"Wave GIF file size ({file_size_mb:.2f} MB) exceeds maximum allowed size (5 MB). Cannot upload."
        log.error(error_msg)
        log.error(f"This file needs to be compressed or replaced in the test_wave_gif_library bucket.")
        raise ValueError(error_msg)
    
    try:
        filename = f"{user_public_id}-wave-gif.gif"
        gif_url = await upload_to_supabase_storage(
            file_content=gif_content,
            filename=filename,
            content_type="image/gif"
        )
        log.info(f"Successfully cloned wave GIF for user {user_public_id}: {gif_url}")
        return gif_url
    except Exception as e:
        log.error(f"Failed to clone wave GIF for user {user_public_id}: {e}")
        raise

def download_photo_v2_image(image_url: str) -> bytes:
    """Download a photo-v2 image from the library."""
    try:
        response = requests.get(image_url, timeout=30)
        response.raise_for_status()
        log.info(f"Successfully downloaded photo-v2 image from {image_url}")
        return response.content
    except requests.RequestException as e:
        log.error(f"Failed to download photo-v2 image from {image_url}: {e}")
        raise

async def clone_photo_v2_to_user(image_content: bytes, user_public_id: str, widget_id: str) -> str:
    """Clone a photo-v2 image to the user's storage location."""
    try:
        # Determine file extension from content or default to jpg
        # Try to detect from content type, but default to jpg
        filename = f"{user_public_id}-bento-{widget_id}.jpg"
        image_url = await upload_to_supabase_storage(
            file_content=image_content,
            filename=filename,
            content_type="image/jpeg"
        )
        log.info(f"Successfully cloned photo-v2 image for user {user_public_id}: {image_url}")
        return image_url
    except Exception as e:
        log.error(f"Failed to clone photo-v2 image for user {user_public_id}: {e}")
        raise

def download_logo(logo_url: str) -> bytes:
    """Download logo from URL."""
    try:
        response = requests.get(logo_url, timeout=30)
        response.raise_for_status()
        log.info(f"Successfully downloaded logo from {logo_url}")
        return response.content
    except requests.RequestException as e:
        log.error(f"Failed to download logo from {logo_url}: {e}")
        raise

# YouTube video captions mapping (video_id -> caption)
YOUTUBE_VIDEO_CAPTIONS = {
    "dQw4w9WgXcQ": "A classic that never gets old!",
    "9bZkp7q19f0": "This one always makes me smile.",
    "kJQP7kiw5Fk": "Perfect for when I need a pick-me-up.",
    "fJ9rUzIMcZQ": "One of my all-time favorites.",
    "OPf0YbXqDm0": "Great for background music while coding.",
    "LXb3EKWsInQ": "This video changed my perspective.",
    "ZbZSe6N_BXs": "I watch this whenever I need inspiration.",
    "ScMzIvxBSi4": "A timeless classic that I keep coming back to.",
    "2Vv-BfVoq4g": "This one always gets me motivated.",
    "YQHsXMglC9A": "Perfect for unwinding after a long day.",
    "FTQbiNvZqaY": "One of the best performances I've seen.",
}

def extract_youtube_video_id(youtube_url: str) -> str:
    """Extract video ID from YouTube URL."""
    if not youtube_url:
        return ""
    patterns = [
        r'(?:youtube\.com\/watch\?v=|youtu\.be\/|youtube\.com\/embed\/)([^&\n?#]+)',
        r'youtube\.com\/v\/([^&\n?#]+)',
        r'youtube\.com\/watch\?.*v=([^&\n?#]+)'
    ]
    for pattern in patterns:
        match = re.search(pattern, youtube_url)
        if match:
            return match.group(1)
    return ""

def get_youtube_thumbnail_url(video_id: str) -> str:
    """Get YouTube thumbnail URL for a video ID."""
    if not video_id:
        return ""
    # Try maxresdefault first (highest quality), fallback to hqdefault
    return f"https://img.youtube.com/vi/{video_id}/maxresdefault.jpg"

def download_youtube_thumbnail(thumbnail_url: str) -> bytes:
    """Download YouTube thumbnail image."""
    try:
        response = requests.get(thumbnail_url, timeout=30)
        response.raise_for_status()
        log.info(f"Successfully downloaded YouTube thumbnail from {thumbnail_url}")
        return response.content
    except requests.RequestException as e:
        log.warning(f"Failed to download YouTube thumbnail from {thumbnail_url}, trying hqdefault: {e}")
        # Fallback to hqdefault if maxresdefault fails
        if "maxresdefault" in thumbnail_url:
            fallback_url = thumbnail_url.replace("maxresdefault", "hqdefault")
            try:
                response = requests.get(fallback_url, timeout=30)
                response.raise_for_status()
                log.info(f"Successfully downloaded YouTube thumbnail from fallback URL: {fallback_url}")
                return response.content
            except requests.RequestException as e2:
                log.error(f"Failed to download YouTube thumbnail from fallback URL {fallback_url}: {e2}")
                raise
        raise

async def clone_youtube_thumbnail_to_user(thumbnail_content: bytes, user_public_id: str, video_id: str) -> str:
    """Clone YouTube thumbnail to the user's storage location."""
    try:
        filename = f"{user_public_id}-video-thumbnail-{video_id}.jpg"
        thumbnail_url = await upload_to_supabase_storage(
            file_content=thumbnail_content,
            filename=filename,
            content_type="image/jpeg"
        )
        log.info(f"Successfully cloned YouTube thumbnail for user {user_public_id}: {thumbnail_url}")
        return thumbnail_url
    except Exception as e:
        log.error(f"Failed to clone YouTube thumbnail for user {user_public_id}: {e}")
        raise

def get_youtube_video_caption(video_id: str) -> str:
    """Get a caption for a YouTube video based on its ID."""
    return YOUTUBE_VIDEO_CAPTIONS.get(video_id, "Currently watching this video.")

def extract_spotify_type_and_id(spotify_url: str) -> tuple[str, str]:
    """
    Extract Spotify type and ID from URL.
    Returns (api_type, item_id) where api_type in ['playlists', 'shows', 'tracks', 'artists', 'albums', 'episodes']
    """
    if 'spotify.com' not in spotify_url:
        return None, None
    
    # Split by '/' and find the type
    parts = spotify_url.split('?')[0].split('#')[0].strip('/').split('/')
    api_map = {
        'playlist': 'playlists',
        'show': 'shows',
        'track': 'tracks',
        'artist': 'artists',
        'album': 'albums',
        'episode': 'episodes',
    }
    
    for i, p in enumerate(parts):
        if p in api_map and i + 1 < len(parts):
            return api_map[p], parts[i + 1]
    return None, None

def get_spotify_client_credentials_token() -> str:
    """Get Spotify access token using client credentials flow."""
    import base64
    SPOTIFY_CLIENT_ID = os.environ.get("SPOTIFY_CLIENT_ID")
    SPOTIFY_CLIENT_SECRET = os.environ.get("SPOTIFY_CLIENT_SECRET")
    
    if not SPOTIFY_CLIENT_ID or not SPOTIFY_CLIENT_SECRET:
        log.warning("SPOTIFY_CLIENT_ID or SPOTIFY_CLIENT_SECRET not set. Spotify images will be skipped.")
        log.debug(f"SPOTIFY_CLIENT_ID present: {bool(SPOTIFY_CLIENT_ID)}, SPOTIFY_CLIENT_SECRET present: {bool(SPOTIFY_CLIENT_SECRET)}")
        return None
    
    token_url = 'https://accounts.spotify.com/api/token'
    basic = base64.b64encode(f"{SPOTIFY_CLIENT_ID}:{SPOTIFY_CLIENT_SECRET}".encode()).decode()
    headers = {
        'Authorization': f'Basic {basic}',
        'Content-Type': 'application/x-www-form-urlencoded',
    }
    data = {'grant_type': 'client_credentials'}
    
    try:
        resp = requests.post(token_url, headers=headers, data=data, timeout=10)
        if not resp.ok:
            log.warning(f"Failed to get Spotify token: {resp.status_code}")
            return None
        return resp.json().get('access_token')
    except Exception as e:
        log.warning(f"Error getting Spotify token: {e}")
        return None

def fetch_spotify_data(spotify_url: str) -> dict:
    """
    Fetch full Spotify data from Spotify API (matching /api/spotify/resolve endpoint exactly).
    Returns a dict with url, name, image, type, etc., or empty dict if unavailable.
    """
    if not spotify_url:
        return {}
    
    api_type, item_id = extract_spotify_type_and_id(spotify_url)
    if not api_type or not item_id:
        log.warning(f"Could not extract type/ID from Spotify URL: {spotify_url}")
        return {}
    
    token = get_spotify_client_credentials_token()
    if not token:
        return {}
    
    endpoint = f"https://api.spotify.com/v1/{api_type}/{item_id}"
    headers = {'Authorization': f'Bearer {token}'}
    
    try:
        r = requests.get(endpoint, headers=headers, timeout=10)
        if not r.ok:
            # 404 can happen for private playlists or invalid IDs
            # Log but don't fail - we'll create a fallback structure
            if r.status_code == 404:
                log.warning(f"Spotify playlist/resource not found (404) for {spotify_url}. May be private or invalid.")
            else:
                log.warning(f"Spotify API error {r.status_code} for {spotify_url}: {r.text[:200]}")
            return {}
        
        data = r.json()
        
        # Map response based on type (matching the app's /api/spotify/resolve endpoint exactly)
        if api_type == 'playlists':
            return {
                "url": f"https://open.spotify.com/playlist/{item_id}",
                "name": data.get('name'),
                "image": (data.get('images') or [{}])[0].get('url') if data.get('images') else None,
                "type": 'playlist',
                "description": data.get('description'),
                "owner": (data.get('owner') or {}).get('display_name'),
                "trackCount": (data.get('tracks') or {}).get('total'),
            }
        elif api_type == 'shows':
            return {
                "url": f"https://open.spotify.com/show/{item_id}",
                "name": data.get('name'),
                "image": (data.get('images') or [{}])[0].get('url') if data.get('images') else None,
                "type": 'podcast',
                "description": data.get('description'),
                "publisher": data.get('publisher'),
                "episodeCount": data.get('total_episodes'),
            }
        elif api_type == 'tracks':
            album = data.get('album') or {}
            artists = data.get('artists') or []
            return {
                "url": f"https://open.spotify.com/track/{item_id}",
                "name": data.get('name'),
                "image": (album.get('images') or [{}])[0].get('url') if album.get('images') else None,
                "type": 'track',
                "artist": (artists[0].get('name') if artists else None),
                "album": album.get('name'),
                "duration": data.get('duration_ms'),
            }
        elif api_type == 'artists':
            return {
                "url": f"https://open.spotify.com/artist/{item_id}",
                "name": data.get('name'),
                "image": (data.get('images') or [{}])[0].get('url') if data.get('images') else None,
                "type": 'artist',
            }
        elif api_type == 'albums':
            artists = data.get('artists') or []
            return {
                "url": f"https://open.spotify.com/album/{item_id}",
                "name": data.get('name'),
                "image": (data.get('images') or [{}])[0].get('url') if data.get('images') else None,
                "type": 'album',
                "artist": (artists[0].get('name') if artists else None),
                "trackCount": data.get('total_tracks'),
            }
        elif api_type == 'episodes':
            show = data.get('show') or {}
            return {
                "url": f"https://open.spotify.com/episode/{item_id}",
                "name": data.get('name'),
                "image": (data.get('images') or [{}])[0].get('url') if data.get('images') else None,
                "type": 'episode',
                "description": data.get('description'),
                "publisher": show.get('publisher'),
                "showName": show.get('name'),
                "duration": data.get('duration_ms'),
            }
        
        return {}
    except Exception as e:
        log.warning(f"Error fetching Spotify data for {spotify_url}: {e}")
        return {}

def fetch_spotify_image_url(spotify_url: str) -> str:
    """
    Fetch Spotify cover art image URL from Spotify API.
    Returns the image URL or empty string if unavailable.
    """
    spotify_data = fetch_spotify_data(spotify_url)
    return spotify_data.get('image', '') if spotify_data else ""

def download_spotify_image(image_url: str) -> bytes:
    """Download Spotify cover art image."""
    try:
        response = requests.get(image_url, timeout=30)
        response.raise_for_status()
        log.info(f"Successfully downloaded Spotify image from {image_url}")
        return response.content
    except requests.RequestException as e:
        log.error(f"Failed to download Spotify image from {image_url}: {e}")
        raise

async def clone_spotify_image_to_user(image_content: bytes, user_public_id: str, spotify_url: str) -> str:
    """Clone Spotify cover art to the user's storage location."""
    try:
        # Extract a simple identifier from the Spotify URL for the filename
        api_type, item_id = extract_spotify_type_and_id(spotify_url)
        if api_type and item_id:
            filename = f"{user_public_id}-spotify-{item_id}.jpg"
        else:
            filename = f"{user_public_id}-spotify-cover.jpg"
        
        image_url = await upload_to_supabase_storage(
            file_content=image_content,
            filename=filename,
            content_type="image/jpeg"
        )
        log.info(f"Successfully cloned Spotify image for user {user_public_id}: {image_url}")
        return image_url
    except Exception as e:
        log.error(f"Failed to clone Spotify image for user {user_public_id}: {e}")
        raise

def read_logo_file(file_path: str) -> bytes:
    """Read logo from local file."""
    try:
        with open(file_path, 'rb') as f:
            content = f.read()
        log.info(f"Successfully read logo file from {file_path}")
        return content
    except FileNotFoundError:
        log.error(f"Logo file not found: {file_path}")
        raise
    except Exception as e:
        log.error(f"Failed to read logo file from {file_path}: {e}")
        raise

async def upload_logo(logo_content: bytes, team_public_id: str, content_type: str = "image/png") -> str:
    """Upload logo to Supabase storage."""
    try:
        filename = f"{team_public_id}-company-logo"
        # Determine file extension from content type
        if "png" in content_type.lower():
            filename += ".png"
        elif "jpg" in content_type.lower() or "jpeg" in content_type.lower():
            filename += ".jpg"
        elif "svg" in content_type.lower():
            filename += ".svg"
        else:
            filename += ".png"  # Default to PNG
        
        logo_url = await upload_to_supabase_storage(
            file_content=logo_content,
            filename=filename,
            content_type=content_type
        )
        log.info(f"Successfully uploaded logo for team {team_public_id}: {logo_url}")
        return logo_url
    except Exception as e:
        log.error(f"Failed to upload logo for team {team_public_id}: {e}")
        raise

def create_team(team_name: str, logo_url: str, team_public_id: str, db: Session) -> Team:
    """Create a new team in the database."""
    log.info(f"Creating team: {team_name} with public_id: {team_public_id}")
    
    team = Team(
        public_id=team_public_id,
        organization_name=team_name,
        company_logo_url=logo_url,
        color_scheme="blue",  # Default color scheme
        color_scheme_data=None,
        slack_settings=None,
        security_settings=None,
        sharing_settings=None,
        custom_prompts=None,
        is_draft=False,
        stripe_customer_id=None,
        stripe_subscription_id=None,
        stripe_subscription_status=None,
        subscription_status="unlimited",  # Set as unlimited for demo
    )
    
    db.add(team)
    db.flush()  # Flush to get the ID
    
    log.info(f"Created team: {team_name} (ID: {team.id}, Public ID: {team_public_id})")
    return team

def create_bento_widgets(user_index: int, location: str, photo_v2_url: str = "", photo_v2_caption: str = "", spotify_url: str = "", spotify_image_url: str = "", spotify_data: dict = None, youtube_url: str = "", video_thumbnail_url: str = "", video_caption: str = "") -> List[Dict[str, Any]]:
    """Create all available bento widgets for a user."""
    widgets = []
    
    # Calculate positions to place widgets in a 3-column grid
    # We'll place them sequentially: row 0, row 1, row 2, etc.
    positions = [
        (0, 0),  # location (1x1)
        (1, 0),  # current-location (1x1)
        (2, 0),  # photo-v2 (1x2) - starts at row 0, spans 2 rows
        (0, 2),  # spotify (2x1) - starts at row 2
        (0, 3),  # video (2x2) - starts at row 3
        (0, 5),  # fun-activities (2x1) - starts at row 5
    ]
    
    for i, widget_type in enumerate(BENTO_WIDGET_TYPES):
        x, y = positions[i] if i < len(positions) else (0, i * 2)
        
        widget = {
            "id": f"widget-{i}-{user_index}",
            "type": widget_type['component'],  # Use component name as type
            "position": {"x": x, "y": y},
            "size": widget_type['defaultSize'],
            "content": None
        }
        
        # Add widget-specific content
        if widget_type['id'] == 'location':
            # "Born and raised" - use a nearby city within ~300km
            birth_location = get_nearby_birth_location(location, user_index)
            widget["content"] = birth_location if birth_location else {"text": f"Born and raised in {location}"}
        elif widget_type['id'] == 'current-location':
            # "Where I live now" - use the user's current location from header
            current_location_data = get_location_data(location)
            widget["content"] = current_location_data if current_location_data else {"text": f"Currently living in {location}"}
        elif widget_type['id'] == 'photo-v2':
            widget["content"] = {
                "text": "My favorite people and pets",
                "url": photo_v2_url,  # Set from uploaded image
                "caption": photo_v2_caption,  # Set based on pet type
                "cropX": 0,
                "cropY": 0,
                "isCropping": False
            }
        elif widget_type['id'] == 'spotify':
            # Spotify widget expects SpotifyData structure (matching /api/spotify/resolve response)
            if spotify_url and spotify_data and spotify_data.get('url'):
                # Use the fetched Spotify data and replace the image URL with our uploaded Supabase URL
                widget_content = spotify_data.copy()
                # Always use the uploaded image URL if available, otherwise keep the original
                if spotify_image_url:
                    widget_content["image"] = spotify_image_url
                elif not widget_content.get('image'):
                    widget_content["image"] = ""
                widget["content"] = widget_content
            elif spotify_url:
                # Fallback if we don't have full Spotify data - create minimal structure
                widget["content"] = {
                    "url": spotify_url,
                    "image": spotify_image_url if spotify_image_url else ""
                }
            else:
                widget["content"] = None
        elif widget_type['id'] == 'video':
            # Extract video ID from YouTube URL
            video_id = extract_youtube_video_id(youtube_url)
            
            widget["content"] = {
                "text": "Currently watching...",
                "youtubeUrl": youtube_url,
                "videoId": video_id,
                "thumbnailUrl": video_thumbnail_url,  # Thumbnail image URL from Supabase
                "caption": video_caption  # User-provided caption
            }
        elif widget_type['id'] == 'fun-activities':
            # Fun-activities widget expects: { activities: [{ emoji: string, caption: string }, ...] }
            # Each user gets 3 activities with emojis and captions
            all_activities = [
                {"emoji": "ðŸ”ï¸", "caption": "hiking and exploring nature"},
                {"emoji": "ðŸŽ²", "caption": "playing board games with friends"},
                {"emoji": "ðŸ³", "caption": "cooking new recipes"},
                {"emoji": "ðŸ“š", "caption": "reading science fiction novels"},
                {"emoji": "ðŸ“¸", "caption": "photography and editing"},
                {"emoji": "ðŸŽ¨", "caption": "painting and drawing"},
                {"emoji": "ðŸŽµ", "caption": "playing musical instruments"},
                {"emoji": "ðŸƒ", "caption": "running and jogging"},
                {"emoji": "ðŸ§˜", "caption": "yoga and meditation"},
                {"emoji": "ðŸŒ±", "caption": "gardening"},
                {"emoji": "âœˆï¸", "caption": "traveling to new places"},
                {"emoji": "ðŸŽ®", "caption": "gaming"},
                {"emoji": "ðŸ‹ï¸", "caption": "weightlifting"},
                {"emoji": "ðŸŽ¬", "caption": "watching movies"},
                {"emoji": "ðŸ•", "caption": "trying new restaurants"},
            ]
            # Deterministically select 3 activities for this user
            random.seed(user_index * 200 + i)
            selected_activities = random.sample(all_activities, 3)
            random.seed()
            widget["content"] = {"activities": selected_activities}
        
        widgets.append(widget)
    
    return widgets

def create_user(
    team_id: int,
    public_id: str,
    name: str,
    role: str,
    location: str,
    greeting: str,
    nickname: str,
    prompts_dict: dict,
    user_index: int,
    wave_gif_url: str,
    photo_v2_url: str,
    photo_v2_caption: str,
    spotify_url: str,
    spotify_image_url: str,
    spotify_data: dict,
    youtube_url: str,
    video_thumbnail_url: str,
    video_caption: str,
    auth_email: str,
    auth_role: str,
    db: Session
) -> WelcomepageUser:
    """Create a welcomepage user with complete data."""
    log.info(f"Creating user: {name} with public_id: {public_id}, auth_email: {auth_email}, auth_role: {auth_role}")
    
    # Use hardcoded prompts and answers from member_data
    selected_prompts = list(prompts_dict.keys())
    answers = {
        prompt: {
            "text": answer_text,
            "image": None,
            "specialData": None,
            "reactions": None
        }
        for prompt, answer_text in prompts_dict.items()
    }
    
    # Create bento widgets with photo-v2 URL, caption, Spotify URL, Spotify image URL, Spotify data, YouTube URL, thumbnail URL, and caption
    bento_widgets = create_bento_widgets(user_index, location, photo_v2_url, photo_v2_caption, spotify_url, spotify_image_url, spotify_data, youtube_url, video_thumbnail_url, video_caption)
    
    # Create handwave emoji (default)
    handwave_emoji = {
        "emoji": "ðŸ‘‹",
        "label": "Default"
    }
    
    user = WelcomepageUser(
        public_id=public_id,
        name=name,
        role=role,
        location=location,
        nickname=nickname,
        greeting=greeting,
        hi_yall_text=None,
        handwave_emoji=handwave_emoji,
        handwave_emoji_url=None,
        profile_photo_url=None,  # TODO: Upload profile photos
        wave_gif_url=wave_gif_url,
        pronunciation_text=None,
        pronunciation_recording_url=None,
        selected_prompts=selected_prompts,
        answers=answers,
        page_comments=None,
        bento_widgets=bento_widgets,
        invite_banner_dismissed=False,
        team_id=team_id,
        is_draft=False,
        auth_role=auth_role,
        auth_email=auth_email,
        slack_user_id=None,
        is_shareable=False,
        share_uuid=None,
    )
    
    db.add(user)
    db.flush()  # Flush to get the ID
    
    log.info(f"Created user {user_index + 1}: {name} ({public_id})")
    return user

def validate_gmail_plus_pattern(email: str) -> tuple[str, int]:
    """
    Validate that the email follows the pattern <email>+<number>@gmail.com
    and extract the base email and number.
    
    Args:
        email: Email address to validate
        
    Returns:
        Tuple of (base_email, number)
        
    Raises:
        ValueError: If email doesn't match the pattern
    """
    # Pattern: <anything>+<digits>@gmail.com
    pattern = r'^(.+)\+(\d+)@gmail\.com$'
    match = re.match(pattern, email)
    
    if not match:
        raise ValueError(
            f"Email '{email}' does not match the required pattern. "
            f"Expected format: <email>+<number>@gmail.com (e.g., charles.barton+2000@gmail.com)"
        )
    
    base_email = match.group(1)
    number = int(match.group(2))
    
    return base_email, number

def generate_auth_email(base_email: str, initial_number: int, user_index: int) -> str:
    """Generate auth_email for a user by incrementing the number."""
    number = initial_number + user_index
    return f"{base_email}+{number}@gmail.com"

async def remove_demo_company(
    prefix: str,
    team_public_id: str,
    user_public_ids: List[str],
    db: Session,
    dry_run: bool = False
) -> None:
    """
    Remove a demo company from the database and Supabase storage.
    This function is RELENTLESS - it will continue even if DB records don't exist,
    and will still attempt to delete files from storage based on expected patterns.
    Only deletes data that matches the prefix pattern for safety.
    
    Args:
        prefix: The 4-character prefix used to identify demo data
        team_public_id: The team public ID to remove
        user_public_ids: List of expected user public IDs (we'll check DB and also try to delete files for all)
        db: Database session
        dry_run: If True, only show what would be deleted without actually deleting
    """
    log.info(f"Starting RELENTLESS removal of demo company with prefix '{prefix}'")
    log.info(f"Team public ID: {team_public_id}")
    log.info(f"Will check for users with prefix and attempt to delete files for expected user IDs")
    
    deleted_users = []
    deleted_files = []
    errors = []
    
    # Generate expected user public IDs if not provided (up to 15 users)
    if not user_public_ids:
        user_public_ids = [f"{prefix}{i+1:03d}" for i in range(15)]
    
    try:
        # Step 1: Find all users with the prefix pattern in database
        log.info("Step 1: Finding all users with matching prefix in database...")
        all_users_with_prefix = db.query(WelcomepageUser).filter(
            WelcomepageUser.public_id.like(f"{prefix}%")
        ).all()
        
        found_user_ids = [user.public_id for user in all_users_with_prefix]
        log.info(f"Found {len(found_user_ids)} users in database with prefix '{prefix}': {found_user_ids[:5]}..." if len(found_user_ids) > 5 else f"Found {len(found_user_ids)} users: {found_user_ids}")
        
        # Create a set of all user IDs we should check (both found in DB and expected)
        all_user_ids_to_check = set(found_user_ids) | set(user_public_ids)
        log.info(f"Will attempt to delete files for {len(all_user_ids_to_check)} user IDs (including orphaned files)")
        
        # Step 2: Delete users from database (must be done before team due to foreign key constraints)
        log.info("Step 2: Deleting users from database...")
        for user in all_users_with_prefix:
            user_public_id = user.public_id
            try:
                if dry_run:
                    log.info(f"DRY RUN: Would delete user {user_public_id} ({user.name})")
                    deleted_users.append(user_public_id)
                else:
                    # Delete user files from Supabase storage
                    # Wave GIF
                    if user.wave_gif_url:
                        try:
                            # Extract filename from URL
                            filename = user.wave_gif_url.split('/')[-1].split('?')[0]
                            # Safety check: only delete if filename starts with user's public_id (which has the prefix)
                            if filename.startswith(user_public_id):
                                log.info(f"Deleting wave GIF: {filename}")
                                success, file_existed = await delete_from_supabase_storage(filename)
                                if success and file_existed:
                                    deleted_files.append(filename)
                                elif not success:
                                    errors.append(f"Failed to delete wave GIF: {filename}")
                            else:
                                log.warning(f"Skipping wave GIF {filename} - doesn't match user public_id pattern")
                        except Exception as e:
                            log.warning(f"Error deleting wave GIF for user {user_public_id}: {e}")
                            errors.append(f"Error deleting wave GIF for {user_public_id}: {str(e)}")
                    
                    # Photo-v2 images (from bento widgets)
                    if user.bento_widgets:
                        try:
                            bento_widgets_list = user.bento_widgets if isinstance(user.bento_widgets, list) else []
                            for widget in bento_widgets_list:
                                if isinstance(widget, dict) and widget.get('type') == 'photo-v2':
                                    photo_url = widget.get('content', {}).get('url', '')
                                    if photo_url:
                                        filename = photo_url.split('/')[-1].split('?')[0]
                                        # Safety check: only delete if filename starts with user's public_id
                                        if filename.startswith(user_public_id):
                                            log.info(f"Deleting photo-v2 image: {filename}")
                                            success, file_existed = await delete_from_supabase_storage(filename)
                                            if success and file_existed:
                                                deleted_files.append(filename)
                                            elif not success:
                                                errors.append(f"Failed to delete photo-v2: {filename}")
                                        else:
                                            log.warning(f"Skipping photo-v2 {filename} - doesn't match user public_id pattern")
                        except Exception as e:
                            log.warning(f"Error deleting photo-v2 images for user {user_public_id}: {e}")
                            errors.append(f"Error deleting photo-v2 for {user_public_id}: {str(e)}")
                    
                    # Delete user from database
                    db.delete(user)
                    log.info(f"Deleted user {user_public_id} ({user.name}) from database")
                    deleted_users.append(user_public_id)
            except Exception as e:
                log.error(f"Error deleting user {user_public_id}: {e}")
                errors.append(f"Error deleting user {user_public_id}: {str(e)}")
                # Continue with other users
        
        # Step 3: Attempt to delete files for ALL expected user IDs (even if not in DB)
        log.info("Step 3: Attempting to delete files from storage for all expected user IDs (including orphaned files)...")
        for user_public_id in all_user_ids_to_check:
            try:
                # Extract user index from public_id (e.g., "ibm-001" -> index 0, "ibm-002" -> index 1)
                # The public_id format is {prefix}{index+1:03d}, so we need to extract the number
                try:
                    # Extract the number part (last 3 digits)
                    user_num_str = user_public_id[-3:]
                    user_index = int(user_num_str) - 1  # Convert to 0-based index
                except (ValueError, IndexError):
                    # If we can't parse, default to 0 (will try widget-2-0)
                    user_index = 0
                    log.warning(f"Could not parse user index from {user_public_id}, using widget-2-0")
                
                # Try to delete wave GIF
                wave_gif_filename = f"{user_public_id}-wave-gif.gif"
                if dry_run:
                    log.info(f"DRY RUN: Would attempt to delete wave GIF: {wave_gif_filename}")
                else:
                    log.info(f"Attempting to delete wave GIF: {wave_gif_filename}")
                    success, file_existed = await delete_from_supabase_storage(wave_gif_filename)
                    if success and file_existed:
                        deleted_files.append(wave_gif_filename)
                        log.info(f"Successfully deleted: {wave_gif_filename}")
                    elif not success:
                        errors.append(f"Failed to delete wave GIF: {wave_gif_filename}")
                    # If file didn't exist, just continue silently
                
                # Try to delete photo-v2 image - use the correct widget ID based on user index
                # Each user has widget-2-{user_index} (e.g., user 0 has widget-2-0, user 1 has widget-2-1)
                widget_id = f"widget-2-{user_index}"
                photo_v2_filename_jpg = f"{user_public_id}-bento-{widget_id}.jpg"
                photo_v2_filename_jpeg = f"{user_public_id}-bento-{widget_id}.jpeg"
                
                if dry_run:
                    log.info(f"DRY RUN: Would attempt to delete photo-v2: {photo_v2_filename_jpg} or {photo_v2_filename_jpeg}")
                else:
                    # Try .jpg first
                    success, file_existed = await delete_from_supabase_storage(photo_v2_filename_jpg)
                    if success and file_existed:
                        deleted_files.append(photo_v2_filename_jpg)
                        log.info(f"Successfully deleted: {photo_v2_filename_jpg}")
                    elif not success:
                        errors.append(f"Failed to delete photo-v2: {photo_v2_filename_jpg}")
                    # Only try .jpeg if .jpg didn't exist (not if it failed)
                    elif success and not file_existed:
                        # .jpg didn't exist, try .jpeg
                        success, file_existed = await delete_from_supabase_storage(photo_v2_filename_jpeg)
                        if success and file_existed:
                            deleted_files.append(photo_v2_filename_jpeg)
                            log.info(f"Successfully deleted: {photo_v2_filename_jpeg}")
                        elif not success:
                            errors.append(f"Failed to delete photo-v2: {photo_v2_filename_jpeg}")
                        # If .jpeg also didn't exist, that's fine - just continue
            except Exception as e:
                log.warning(f"Error attempting to delete files for user {user_public_id}: {e}")
                errors.append(f"Error deleting files for {user_public_id}: {str(e)}")
                # Continue with next user
        
        # Step 4: Find and delete team from database (safety: only delete if public_id matches expected pattern)
        log.info("Step 4: Deleting team from database...")
        try:
            team = db.query(Team).filter_by(public_id=team_public_id).first()
            if team:
                if dry_run:
                    log.info(f"DRY RUN: Would delete team {team_public_id} ({team.organization_name})")
                else:
                    # Delete team logo from Supabase storage (if URL exists in DB)
                    if team.company_logo_url:
                        try:
                            # Extract filename from URL
                            filename = team.company_logo_url.split('/')[-1].split('?')[0]
                            # Safety check: only delete if filename starts with team_public_id (which has the prefix)
                            if filename.startswith(team_public_id):
                                log.info(f"Deleting team logo: {filename}")
                                success, file_existed = await delete_from_supabase_storage(filename)
                                if success and file_existed:
                                    deleted_files.append(filename)
                                elif not success:
                                    errors.append(f"Failed to delete team logo: {filename}")
                            else:
                                log.warning(f"Skipping team logo {filename} - doesn't match team public_id pattern")
                        except Exception as e:
                            log.warning(f"Error deleting team logo: {e}")
                            errors.append(f"Error deleting team logo: {str(e)}")
                    
                    # Delete team from database
                    db.delete(team)
                    log.info(f"Deleted team {team_public_id} ({team.organization_name}) from database")
            else:
                log.info(f"Team {team_public_id} not found in database - will still attempt to delete logo file")
        except Exception as e:
            log.error(f"Error deleting team {team_public_id}: {e}")
            errors.append(f"Error deleting team {team_public_id}: {str(e)}")
        
        # Step 5: Attempt to delete team logo file even if team not in DB
        log.info("Step 5: Attempting to delete team logo from storage (even if team not in DB)...")
        try:
            # Try common logo filename patterns
            logo_filename_patterns = [
                f"{team_public_id}-company-logo.png",
                f"{team_public_id}-company-logo.jpg",
                f"{team_public_id}-company-logo.jpeg",
                f"{team_public_id}-company-logo.svg",
            ]
            
            for logo_filename in logo_filename_patterns:
                if dry_run:
                    log.info(f"DRY RUN: Would attempt to delete team logo: {logo_filename}")
                else:
                    log.info(f"Attempting to delete team logo: {logo_filename}")
                    success, file_existed = await delete_from_supabase_storage(logo_filename)
                    if success and file_existed:
                        deleted_files.append(logo_filename)
                        log.info(f"Successfully deleted: {logo_filename}")
                        # Found and deleted the logo, no need to try other extensions
                        break
                    elif not success:
                        errors.append(f"Failed to delete team logo: {logo_filename}")
                    # If file didn't exist, try next extension
        except Exception as e:
            log.warning(f"Error attempting to delete team logo files: {e}")
            errors.append(f"Error deleting team logo files: {str(e)}")
        
        # Step 6: Commit database changes (if not dry run)
        if not dry_run:
            try:
                db.commit()
                log.info("Database changes committed successfully")
            except Exception as e:
                log.error(f"Error committing database changes: {e}")
                db.rollback()
                errors.append(f"Error committing database changes: {str(e)}")
        
        # Print summary
        print("\n" + "="*60)
        print("DEMO COMPANY REMOVAL SUMMARY")
        print("="*60)
        if dry_run:
            print("DRY RUN - No changes were made")
        print(f"Prefix: {prefix}")
        print(f"Team Public ID: {team_public_id}")
        print(f"Users deleted: {len(deleted_users)}")
        if deleted_users:
            print(f"  - {', '.join(deleted_users[:5])}" + ("..." if len(deleted_users) > 5 else ""))
        print(f"Files deleted from storage: {len(deleted_files)}")
        if deleted_files:
            print(f"  - {', '.join(deleted_files[:5])}" + ("..." if len(deleted_files) > 5 else ""))
        if errors:
            print(f"\nWarnings/Errors ({len(errors)}):")
            for error in errors[:10]:
                print(f"  - {error}")
            if len(errors) > 10:
                print(f"  ... and {len(errors) - 10} more errors")
        print("="*60)
        
    except Exception as e:
        log.error(f"Unexpected error during demo company removal: {e}")
        if not dry_run:
            try:
                db.rollback()
            except:
                pass
        raise

def build_team_json_record(
    team_name: str,
    team_public_id: str,
    logo_url: str
) -> Dict[str, Any]:
    """Build a complete team record as a dictionary for JSON output."""
    return {
        "public_id": team_public_id,
        "organization_name": team_name,
        "company_logo_url": logo_url,
        "color_scheme": "blue",
        "color_scheme_data": None,
        "slack_settings": None,
        "security_settings": None,
        "sharing_settings": None,
        "custom_prompts": None,
        "is_draft": False,
        "stripe_customer_id": None,
        "stripe_subscription_id": None,
        "stripe_subscription_status": None,
        "subscription_status": "unlimited"
    }

def build_user_json_record(
    public_id: str,
    name: str,
    role: str,
    location: str,
    greeting: str,
    nickname: str,
    prompts_dict: dict,
    user_index: int,
    team_id: int,
    wave_gif_url: str,
    photo_v2_url: str,
    photo_v2_caption: str,
    spotify_url: str,
    youtube_url: str,
    auth_email: str,
    auth_role: str,
    bento_widgets: List[Dict[str, Any]]
) -> Dict[str, Any]:
    """Build a complete user record as a dictionary for JSON output."""
    
    # Build answers dict
    answers = {
        prompt: {
            "text": answer_text,
            "image": None,
            "specialData": None,
            "reactions": None
        }
        for prompt, answer_text in prompts_dict.items()
    }
    
    # Build handwave emoji
    handwave_emoji = {
        "emoji": "ðŸ‘‹",
        "label": "Default"
    }
    
    return {
        "public_id": public_id,
        "name": name,
        "role": role,
        "location": location,
        "nickname": nickname,
        "greeting": greeting,
        "hi_yall_text": None,
        "handwave_emoji": handwave_emoji,
        "handwave_emoji_url": None,
        "profile_photo_url": None,
        "wave_gif_url": wave_gif_url,
        "pronunciation_text": None,
        "pronunciation_recording_url": None,
        "selected_prompts": list(prompts_dict.keys()),
        "answers": answers,
        "page_comments": None,
        "bento_widgets": bento_widgets,
        "invite_banner_dismissed": False,
        "team_id": team_id,
        "is_draft": False,
        "auth_role": auth_role,
        "auth_email": auth_email,
        "slack_user_id": None,
        "is_shareable": False,
        "share_uuid": None
    }

async def main_async():
    parser = argparse.ArgumentParser(description="Create or remove a demo company with welcomepage users")
    parser.add_argument("--team-name", help="Name of the team/company (required for creation, not for removal)")
    parser.add_argument("--prefix", required=True, help="4-character prefix for public IDs (e.g., 'ibm-' or 'dem1')")
    parser.add_argument("--logo-url", help="URL to the company logo (will be downloaded and uploaded to Supabase)")
    parser.add_argument("--logo-file", help="Path to local logo file (will be uploaded to Supabase)")
    parser.add_argument("--team-size", type=int, default=15, help="Number of team members to create (2-15, default: 15). Not used with --remove.")
    parser.add_argument("--initial-email", help="Initial Gmail address with +number pattern (e.g., charles.barton+2000@gmail.com). Required for creation, not for removal.")
    parser.add_argument("--dry-run", action="store_true", help="Show what would be created/deleted without actually doing it")
    parser.add_argument("--remove", action="store_true", help="Remove the demo company instead of creating it. Deletes team, users, and all associated files from database and Supabase storage.")
    
    args = parser.parse_args()
    
    # Validate prefix (must be exactly 4 characters)
    if len(args.prefix) != 4:
        parser.error(f"Prefix must be exactly 4 characters. Got '{args.prefix}' ({len(args.prefix)} characters)")
    
    # Validate required parameters based on mode
    if args.remove:
        # For removal, only prefix is required
        if args.team_name:
            log.warning("--team-name is not needed for removal and will be ignored")
        if args.initial_email:
            log.warning("--initial-email is not needed for removal and will be ignored")
        if args.logo_url or args.logo_file:
            log.warning("Logo parameters are not needed for removal and will be ignored")
    else:
        # For creation, validate required parameters
        if not args.team_name:
            parser.error("--team-name is required for creation")
        if not args.initial_email:
            parser.error("--initial-email is required for creation")
        if not args.logo_url and not args.logo_file:
            parser.error("Either --logo-url or --logo-file must be provided for creation")
        if args.logo_url and args.logo_file:
            parser.error("Cannot specify both --logo-url and --logo-file. Please provide only one.")
        
        # Validate initial email pattern
        try:
            base_email, initial_number = validate_gmail_plus_pattern(args.initial_email)
            log.info(f"Validated initial email: {args.initial_email} -> base: {base_email}, number: {initial_number}")
        except ValueError as e:
            parser.error(str(e))
    
    # Construct public IDs from prefix
    team_public_id = f"{args.prefix}team01"
    
    if args.remove:
        # For removal, we'll query for all users with the prefix pattern dynamically
        # We don't need to know the exact count - the removal function will find them all
        user_public_ids = []  # Will be populated by querying database
        log.info(f"Starting demo company removal: prefix={args.prefix}, team_public_id={team_public_id}, dry_run={args.dry_run}")
    else:
        # For creation, use the specified team_size
        user_public_ids = [f"{args.prefix}{i+1:03d}" for i in range(args.team_size)]
        log.info(f"Starting demo company creation: team_name={args.team_name}, prefix={args.prefix}, team_public_id={team_public_id}, logo_url={args.logo_url}, logo_file={args.logo_file}, team_size={args.team_size}, initial_email={args.initial_email}, dry_run={args.dry_run}")
        
        # Validate team size (only for creation)
        if args.team_size < 2 or args.team_size > 15:
            log.error("Team size must be between 2 and 15")
            sys.exit(1)
        
        if args.team_size > len(TEAM_MEMBERS):
            log.warning(f"Team size ({args.team_size}) exceeds available member data ({len(TEAM_MEMBERS)}). Using all available members.")
            args.team_size = len(TEAM_MEMBERS)
    
    db = SessionLocal()
    try:
        # Handle removal
        if args.remove:
            # For removal, pass empty list - the function will query for all users with the prefix
            await remove_demo_company(args.prefix, team_public_id, [], db, dry_run=args.dry_run)
            return
        
        # Start a transaction - all database operations will be in a single transaction
        # If any error occurs, everything will be rolled back
        # Public IDs are constructed from prefix (already done above)
        log.info(f"Team public ID: {team_public_id}")
        log.info(f"User public IDs: {user_public_ids[:3]}..." if len(user_public_ids) > 3 else f"User public IDs: {user_public_ids}")
        
        # Step 0.1: Generate auth_emails for all users
        log.info("Generating auth_emails...")
        auth_emails = [
            generate_auth_email(base_email, initial_number, i)
            for i in range(args.team_size)
        ]
        log.info(f"Auth emails: {auth_emails[:3]}..." if len(auth_emails) > 3 else f"Auth emails: {auth_emails}")
        
        # Step 0.5: Check for collisions before creating anything
        log.info("Checking for public ID collisions...")
        has_public_id_collisions, public_id_collisions = check_public_id_collisions(db, team_public_id, user_public_ids)
        
        log.info("Checking for auth_email collisions...")
        has_auth_email_collisions, auth_email_collisions = check_auth_email_collisions(db, auth_emails)
        
        all_collisions = []
        if has_public_id_collisions:
            all_collisions.extend(public_id_collisions)
        if has_auth_email_collisions:
            all_collisions.extend(auth_email_collisions)
        
        if all_collisions:
            log.error("Collisions detected! Cannot proceed.")
            print("\n" + "="*60)
            print("COLLISION DETECTED - Cannot create demo company")
            print("="*60)
            print("The following conflicts already exist in the database:")
            for collision in all_collisions:
                print(f"  - {collision}")
            print("\nPlease choose a different initial email or remove the existing records.")
            print("="*60)
            sys.exit(1)
        
        log.info("No collisions detected. Proceeding with creation...")
        
        # Step 1: Get logo content and upload (happens before database transaction)
        # Note: File uploads are external operations. If they fail, we won't proceed to database operations.
        # If database operations fail after uploads, files may be orphaned but database will be rolled back.
        if args.logo_file:
            log.info(f"Reading logo from local file: {args.logo_file}")
            if not args.dry_run:
                logo_content = read_logo_file(args.logo_file)
                # Determine content type from file extension
                content_type = "image/png"
                file_lower = args.logo_file.lower()
                if file_lower.endswith('.jpg') or file_lower.endswith('.jpeg'):
                    content_type = "image/jpeg"
                elif file_lower.endswith('.svg'):
                    content_type = "image/svg+xml"
                elif file_lower.endswith('.gif'):
                    content_type = "image/gif"
                elif file_lower.endswith('.webp'):
                    content_type = "image/webp"
                
                uploaded_logo_url = await upload_logo(logo_content, team_public_id, content_type)
            else:
                uploaded_logo_url = f"file://{args.logo_file}"  # Use file path in dry-run
        else:
            log.info(f"Downloading logo from URL: {args.logo_url}")
            if not args.dry_run:
                logo_content = download_logo(args.logo_url)
                # Determine content type from URL or default to PNG
                content_type = "image/png"
                if args.logo_url.lower().endswith('.jpg') or args.logo_url.lower().endswith('.jpeg'):
                    content_type = "image/jpeg"
                elif args.logo_url.lower().endswith('.svg'):
                    content_type = "image/svg+xml"
                elif args.logo_url.lower().endswith('.gif'):
                    content_type = "image/gif"
                elif args.logo_url.lower().endswith('.webp'):
                    content_type = "image/webp"
                
                uploaded_logo_url = await upload_logo(logo_content, team_public_id, content_type)
            else:
                uploaded_logo_url = args.logo_url  # Use provided URL in dry-run
        
        # Step 2: Create team (database operation - part of transaction)
        log.info("Creating team in database...")
        if args.dry_run:
            team_id = 1  # Dummy ID for dry run
            team_record = build_team_json_record(args.team_name, team_public_id, uploaded_logo_url)
        else:
            team = create_team(args.team_name, uploaded_logo_url, team_public_id, db)
            team_id = team.id
            log.info(f"Team added to transaction (will be committed at end): {team_public_id}")
        
        # Step 3: Create users (all database operations - part of same transaction)
        log.info(f"Creating {args.team_size} users in database...")
        created_users = []
        user_records = []  # For JSON output in dry-run
        
        for i in range(args.team_size):
            member_data = TEAM_MEMBERS[i]
            public_id = user_public_ids[i]  # Use constructed public ID from prefix
            name, role, location, greeting, nickname, prompts_dict = member_data
            log.info(f"Processing user {i+1}/{args.team_size}: {name} (ID: {public_id})")
            
            # Get wave GIF (deterministic based on user index)
            wave_gif_url = get_wave_gif_url_for_user(i)
            log.info(f"Selected wave GIF for user {i+1}: {wave_gif_url}")
            
            # Get photo-v2 image URL and caption
            # Use user_index to get the library URL (uses hardcoded demo001, demo002, etc.)
            photo_v2_library_url = get_photo_v2_url_for_user(i)
            photo_v2_caption = get_photo_v2_caption(i)
            
            # Get Spotify and YouTube URLs for this user
            spotify_url = SAMPLE_SPOTIFY_URLS[i] if i < len(SAMPLE_SPOTIFY_URLS) else ""
            youtube_url = SAMPLE_YOUTUBE_URLS[i] if i < len(SAMPLE_YOUTUBE_URLS) else ""
            
            # Extract video ID and get thumbnail/caption for YouTube video
            video_id = extract_youtube_video_id(youtube_url)
            video_caption = get_youtube_video_caption(video_id) if video_id else ""
            
            # Generate auth_email for this user (before the if/else so it's available in both branches)
            auth_email = generate_auth_email(base_email, initial_number, i)
            # First user (index 0) gets ADMIN role, rest get USER role
            auth_role = "ADMIN" if i == 0 else "USER"
            
            if args.dry_run:
                # Build bento widgets for JSON output
                # For dry-run, show what the final URLs would be (after upload to user storage)
                # These would be Supabase storage URLs, but we show the library URLs for reference
                # In actual run, these would be uploaded and replaced with storage URLs
                final_wave_gif_url = wave_gif_url  # Will be uploaded to: {public_id}-wave-gif.gif
                widget_id = f"widget-2-{i}"  # photo-v2 is at index 2
                final_photo_v2_url = photo_v2_library_url  # Will be uploaded to: {public_id}-bento-{widget_id}.jpg
                
                # For dry-run, show what the thumbnail URL would be (after upload)
                # In actual run, this would be uploaded to: {public_id}-video-thumbnail-{video_id}.jpg
                final_video_thumbnail_url = f"[Would be uploaded to: {public_id}-video-thumbnail-{video_id}.jpg]" if video_id else ""
                
                # For dry-run, show what the Spotify image URL would be (after upload)
                # In actual run, this would be uploaded to: {public_id}-spotify-{item_id}.jpg
                final_spotify_image_url = f"[Would be uploaded to: {public_id}-spotify-cover.jpg]" if spotify_url else ""
                
                # Fetch full Spotify data for dry-run (for widget structure)
                spotify_data = fetch_spotify_data(spotify_url) if spotify_url else None
                
                bento_widgets = create_bento_widgets(i, location, final_photo_v2_url, photo_v2_caption, spotify_url, final_spotify_image_url, spotify_data, youtube_url, final_video_thumbnail_url, video_caption)
                
                # Build complete user record
                user_record = build_user_json_record(
                    public_id, name, role, location, greeting, nickname, prompts_dict,
                    i, team_id, final_wave_gif_url, final_photo_v2_url,
                    photo_v2_caption, spotify_url, youtube_url, auth_email, auth_role, bento_widgets
                )
                user_records.append(user_record)
                
                created_users.append({
                    'public_id': public_id,
                    'name': name,
                    'auth_email': auth_email,
                    'auth_role': auth_role,
                    'wave_gif_url': wave_gif_url,
                    'photo_v2_url': photo_v2_library_url,
                    'photo_v2_caption': photo_v2_caption
                })
            else:
                # Download and clone wave GIF (external operation - not part of DB transaction)
                gif_content = download_wave_gif(wave_gif_url)
                cloned_gif_url = await clone_wave_gif_to_user(gif_content, public_id)
                
                # Download and clone photo-v2 image (external operation - not part of DB transaction)
                photo_v2_content = download_photo_v2_image(photo_v2_library_url)
                widget_id = f"widget-2-{i}"  # photo-v2 is at index 2
                cloned_photo_v2_url = await clone_photo_v2_to_user(photo_v2_content, public_id, widget_id)
                
                # Download and clone YouTube thumbnail (external operation - not part of DB transaction)
                cloned_video_thumbnail_url = ""
                if video_id:
                    try:
                        thumbnail_url = get_youtube_thumbnail_url(video_id)
                        thumbnail_content = download_youtube_thumbnail(thumbnail_url)
                        cloned_video_thumbnail_url = await clone_youtube_thumbnail_to_user(thumbnail_content, public_id, video_id)
                        log.info(f"Successfully downloaded and uploaded YouTube thumbnail for user {public_id}")
                    except Exception as e:
                        log.warning(f"Failed to download/upload YouTube thumbnail for user {public_id}: {e}. Continuing without thumbnail.")
                        cloned_video_thumbnail_url = ""
                
                # Download and clone Spotify cover art (external operation - not part of DB transaction)
                cloned_spotify_image_url = ""
                spotify_data = None
                if spotify_url:
                    try:
                        # Fetch full Spotify data (name, type, etc.) for widget structure
                        spotify_data = fetch_spotify_data(spotify_url)
                        # Check if we got valid data (not empty dict) and it has required fields
                        if spotify_data and spotify_data.get('url') and spotify_data.get('name'):
                            # We have valid Spotify data with name - try to get image
                            if spotify_data.get('image'):
                                spotify_image_url = spotify_data.get('image')
                                try:
                                    spotify_image_content = download_spotify_image(spotify_image_url)
                                    cloned_spotify_image_url = await clone_spotify_image_to_user(spotify_image_content, public_id, spotify_url)
                                    # Update spotify_data with our uploaded image URL
                                    spotify_data["image"] = cloned_spotify_image_url
                                    log.info(f"Successfully downloaded and uploaded Spotify image for user {public_id}")
                                except Exception as img_error:
                                    log.warning(f"Failed to download/upload Spotify image for user {public_id}: {img_error}. Keeping original image URL.")
                                    # Keep the original Spotify image URL if upload fails
                                    spotify_data["image"] = spotify_image_url
                            else:
                                # No image available from Spotify API
                                log.warning(f"Spotify data fetched but no image available for {spotify_url}. Continuing without image.")
                                spotify_data["image"] = ""
                        else:
                            # fetch_spotify_data returned empty dict or missing required fields
                            # This usually means Spotify credentials are not set or API call failed
                            log.warning(f"Could not fetch Spotify data for {spotify_url}. Spotify credentials may not be set. Creating minimal structure.")
                            # Extract type from URL as fallback
                            api_type, item_id = extract_spotify_type_and_id(spotify_url)
                            type_map = {
                                'playlists': 'playlist',
                                'shows': 'podcast',
                                'tracks': 'track',
                                'artists': 'artist',
                                'albums': 'album',
                                'episodes': 'episode'
                            }
                            spotify_type = type_map.get(api_type, 'playlist') if api_type else 'playlist'
                            # Create a proper structure with at least required fields
                            spotify_data = {
                                "url": spotify_url,
                                "name": f"Spotify {spotify_type.title()}",  # Fallback name
                                "type": spotify_type,
                                "image": ""
                            }
                    except Exception as e:
                        log.warning(f"Failed to process Spotify data for user {public_id}: {e}. Creating minimal structure.")
                        cloned_spotify_image_url = ""
                        # Extract type from URL as fallback
                        api_type, item_id = extract_spotify_type_and_id(spotify_url)
                        type_map = {
                            'playlists': 'playlist',
                            'shows': 'podcast',
                            'tracks': 'track',
                            'artists': 'artist',
                            'albums': 'album',
                            'episodes': 'episode'
                        }
                        spotify_type = type_map.get(api_type, 'playlist') if api_type else 'playlist'
                        spotify_data = {
                            "url": spotify_url,
                            "name": f"Spotify {spotify_type.title()}",  # Fallback name
                            "type": spotify_type,
                            "image": ""
                        } if spotify_url else None
                
                # Create user (database operation - part of transaction)
                user = create_user(team_id, public_id, name, role, location, greeting, nickname, prompts_dict, i, cloned_gif_url, cloned_photo_v2_url, photo_v2_caption, spotify_url, cloned_spotify_image_url, spotify_data, youtube_url, cloned_video_thumbnail_url, video_caption, auth_email, auth_role, db)
                log.info(f"User {i+1} added to transaction (will be committed at end): {public_id}")
                
                # Store both the user object (for search_vector update) and summary dict
                created_users.append({
                    'user_obj': user,  # Store user object for search_vector update
                    'id': user.id,
                    'public_id': user.public_id,
                    'name': user.name,
                    'auth_email': user.auth_email,
                    'auth_role': user.auth_role,
                    'wave_gif_url': cloned_gif_url
                })
        
        # Step 4: Commit all database changes in a single transaction
        # All database operations (team + all users) are committed together
        # If any error occurred above, we'll rollback in the except block
        if not args.dry_run:
            log.info("Committing transaction - all database changes will be made permanent")
            db.commit()
            log.info(f"Successfully created team '{args.team_name}' with {args.team_size} users")
            log.info("Transaction committed successfully - all database changes are now permanent")
            
            # Step 5: Update search_vector for all users (required for search to work)
            # This must be done after commit so users have IDs, following the same pattern as the app
            log.info("Updating search_vector for all users...")
            from utils.search_vector import update_search_vector
            for user_data in created_users:
                user = user_data['user_obj']
                # Refresh to ensure we have the latest user object with ID
                db.refresh(user)
                # Update search_vector (this generates search text and creates tsvector)
                update_search_vector(db, user)
                log.info(f"Updated search_vector for user {user.public_id} ({user.name})")
            # Commit the search_vector updates
            db.commit()
            log.info("Successfully updated search_vector for all users")
        else:
            log.info(f"DRY RUN: Would have created team '{args.team_name}' with {args.team_size} users")
            
            # Print JSON records for dry-run
            print("\n" + "="*60)
            print("DRY RUN - JSON RECORDS TO BE INSERTED")
            print("="*60)
            print("\nTEAM RECORD (teams table):")
            print(json.dumps(team_record, indent=2, ensure_ascii=False))
            print("\n" + "-"*60)
            print(f"\nUSER RECORDS (welcomepage_users table) - {len(user_records)} records:")
            print(json.dumps(user_records, indent=2, ensure_ascii=False))
            print("="*60)
        
        # Print summary
        print("\n" + "="*60)
        print("DEMO COMPANY CREATION SUMMARY")
        print("="*60)
        print(f"Team: {args.team_name}")
        if not args.dry_run:
            print(f"Team Public ID: {team_public_id}")
        print(f"Logo URL: {uploaded_logo_url}")
        print(f"Created users: {len(created_users)}")
        print("\nCreated users:")
        for user in created_users:
            print(f"  - {user['name']} ({user['public_id']})")
            print(f"    Auth Email: {user.get('auth_email', 'N/A')}")
            print(f"    Auth Role: {user.get('auth_role', 'N/A')}")
            if not args.dry_run:
                print(f"    Wave GIF: {user['wave_gif_url']}")
        print("="*60)
        print("\nAll features implemented:")
        print("  âœ“ Wave GIFs: Downloaded from test_wave_gif_library and uploaded to user storage")
        print("  âœ“ Bento widget images: Photo-v2 images downloaded and uploaded with pet-specific captions")
        print("  âœ“ Spotify URLs: Sample playlists, tracks, and shows assigned to each user")
        print("  âœ“ YouTube URLs: Sample videos assigned to each user with video ID extraction")
        print("="*60)
        
    except Exception as e:
        log.error(f"Error during demo company creation: {e}")
        if not args.dry_run:
            log.error("Rolling back transaction - no database changes will be committed")
            db.rollback()
            log.info("Transaction rolled back successfully - database is in original state")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    finally:
        db.close()

def main():
    asyncio.run(main_async())

if __name__ == "__main__":
    main()
